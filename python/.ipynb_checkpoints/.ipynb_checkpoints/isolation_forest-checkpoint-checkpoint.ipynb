{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, confusion_matrix\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import LSTM, Flatten, Dense, Conv1D, Conv2D, CuDNNLSTM, Dropout, BatchNormalization, Activation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import load_model, Model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import LSTM, Flatten, Dense, Conv1D, Conv2D, CuDNNLSTM, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime, timedelta\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import warnings\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "import json\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../resource/normal_pressure.csv\n",
      "../resource/burst_pressure.csv\n",
      "../resource/normal_pressure_mean.csv\n",
      "../resource/burst_pressure_simularity.csv\n",
      "5\n",
      "0.7\n",
      "0.0125\n"
     ]
    }
   ],
   "source": [
    "with open('../resource/config.json') as f:\n",
    "    jsonDict = json.load(f)\n",
    "normalPressureFile = '../' + jsonDict['normalPressureFile']\n",
    "burstPressureFile = '../' + jsonDict['burstPressureFile']\n",
    "normalPressureMeanFile = '../' + jsonDict['normalPressureMeanFile']\n",
    "burstPressureSimularityFile = '../' + jsonDict['burstPressureSimularityFile']\n",
    "windowSize = jsonDict['windowSize']\n",
    "trainSetPercent = jsonDict['trainSetPercent']\n",
    "abnormalPercent = jsonDict['abnormalPercent']\n",
    "print(normalPressureFile)\n",
    "print(burstPressureFile)\n",
    "print(normalPressureMeanFile)\n",
    "print(burstPressureSimularityFile)\n",
    "print(windowSize)\n",
    "print(trainSetPercent)\n",
    "print(abnormalPercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 95995/95995 [00:22<00:00, 4331.51it/s]\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(burstPressureSimularityFile, names=['value'])\n",
    "data = pd.DataFrame(data=np.zeros((len(rawData) - windowSize + 1, windowSize)))\n",
    "for i in tqdm(range(windowSize, len(rawData))):\n",
    "    data.iloc[i-windowSize, :] = np.array(rawData.iloc[i - windowSize:i, 0])\n",
    "splitIndex = math.ceil(len(data)*trainSetPercent)\n",
    "X_train = data.iloc[:splitIndex, :].values\n",
    "X_test = data.iloc[splitIndex:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1,  1, -1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IsolationForest(n_estimators=300, contamination=abnormalPercent, random_state=42)\n",
    "model.fit(X_train)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 28537, -1: 261})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
